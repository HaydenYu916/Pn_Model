import numpy as np
import requests
import json
import re
import time
from pymoo.core.crossover import Crossover


class GPT_OpenAI(Crossover):
    """
    åŸºäºOpenAIå®˜æ–¹APIæ–‡æ¡£æ ‡å‡†çš„GPTäº¤å‰ç®—å­
    https://platform.openai.com/docs/api-reference/introduction
    """

    def __init__(self, n_new, **kwargs):
        super().__init__(10, 2, **kwargs)
        self.n_new = n_new

    def get_prompt(self, x, y, obj_p):
        """æ„å»ºæç¤ºå†…å®¹"""
        pop_content = " "
        for i in range(len(x)):
            pop_content += "point: <start>" + ",".join(str(idx) for idx in x[i].tolist()) + "<end> \n objective 1: " + str(round(obj_p[i][0], 4)) + " objective 2: " + str(round(obj_p[i][1], 4)) + "\n\n"
        
        prompt_content = ("Now you will help me minimize " + str(len(obj_p[0])) + " objectives with " + str(len(x[0])) + " variables. "
                         "I have some points with their objective values. The points start with <start> and end with <end>.\n\n"
                         + pop_content +
                         "Give me two new points that are different from all points above, and not dominated by any of the above. "
                         "Do not write code. Do not give any explanation. Each output new point must start with <start> and end with <end>")
        return prompt_content

    def call_openai_api(self, prompt, model_LLM, endpoint, key, max_retries=5):
        """
        æ ¹æ®OpenAIå®˜æ–¹æ–‡æ¡£è°ƒç”¨API
        https://platform.openai.com/docs/api-reference/chat/create
        """
        # æ„å»ºæ ‡å‡†çš„OpenAI API URL
        if endpoint.startswith('http'):
            url = f"{endpoint}/v1/chat/completions"
        else:
            url = f"https://{endpoint}/v1/chat/completions"
        
        # æ ‡å‡†çš„OpenAI API headers
        headers = {
            "Authorization": f"Bearer {key}",
            "Content-Type": "application/json"
        }
        
        # æ ‡å‡†çš„OpenAI API payload
        data = {
            "model": model_LLM,
            "messages": [
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "max_tokens": 1000,
            "temperature": 0.7
        }
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ è°ƒç”¨API (å°è¯• {attempt + 1}/{max_retries})...")
                
                response = requests.post(url, headers=headers, json=data, timeout=30)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    if 'choices' in result and len(result['choices']) > 0:
                        content = result['choices'][0]['message']['content']
                        print(f"âœ… APIè°ƒç”¨æˆåŠŸ")
                        return content
                    else:
                        print(f"âŒ APIå“åº”æ ¼å¼é”™è¯¯: {result}")
                        continue
                        
                elif response.status_code == 401:
                    print(f"âŒ APIå¯†é’¥æ— æ•ˆ: {response.text}")
                    break
                    
                elif response.status_code == 429:
                    print(f"âš ï¸  APIè°ƒç”¨é™åˆ¶ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
                    
                else:
                    print(f"âŒ APIè°ƒç”¨å¤±è´¥ ({response.status_code}): {response.text}")
                    time.sleep(2)
                    continue
                    
            except requests.exceptions.Timeout:
                print(f"â° APIè°ƒç”¨è¶…æ—¶ï¼Œé‡è¯•ä¸­...")
                time.sleep(2)
                continue
                
            except requests.exceptions.ConnectionError:
                print(f"ğŸŒ ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œé‡è¯•ä¸­...")
                time.sleep(2)
                continue
                
            except Exception as e:
                print(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")
                time.sleep(2)
                continue
        
        print(f"âŒ APIè°ƒç”¨å¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
        return None

    def call_ollama_api(self, prompt, model_LLM, endpoint, max_retries=3):
        """
        è°ƒç”¨Ollamaæœ¬åœ°API
        """
        if endpoint.startswith('http'):
            url = f"{endpoint}/api/chat"
        else:
            url = f"http://{endpoint}/api/chat"
        
        headers = {
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model_LLM,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "stream": False
        }
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ è°ƒç”¨Ollama (å°è¯• {attempt + 1}/{max_retries})...")
                
                response = requests.post(url, headers=headers, json=data, timeout=60)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    if 'message' in result and 'content' in result['message']:
                        content = result['message']['content']
                        print(f"âœ… Ollamaè°ƒç”¨æˆåŠŸ")
                        return content
                    else:
                        print(f"âŒ Ollamaå“åº”æ ¼å¼é”™è¯¯: {result}")
                        continue
                else:
                    print(f"âŒ Ollamaè°ƒç”¨å¤±è´¥ ({response.status_code}): {response.text}")
                    time.sleep(2)
                    continue
                    
            except Exception as e:
                print(f"âŒ Ollamaè°ƒç”¨é”™è¯¯: {str(e)}")
                time.sleep(2)
                continue
        
        print(f"âŒ Ollamaè°ƒç”¨å¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
        return None

    def _do(self, _, X, Y, debug_mode, model_LLM, endpoint, key, out_filename, parents_obj, **kwargs):
        """æ‰§è¡Œäº¤å‰æ“ä½œ"""
        
        # æ•°æ®é¢„å¤„ç†
        y_p = np.zeros(len(Y))
        x_p = np.zeros((len(X), len(X[0][0])))
        
        for i in range(len(Y)):
            y_p[i] = round(Y[i][0][0], 4)
            x_p[i] = X[i][0]
            x_p[i] = np.round((x_p[i] - _.xl) / (_.xu - _.xl), 4)

        # æ’åº
        sort_idx = sorted(range(len(Y)), key=lambda k: Y[k], reverse=True)
        x_p = [x_p[idx] for idx in sort_idx]
        y_p = [y_p[idx] for idx in sort_idx]
        obj_p = parents_obj[0][:10].get("F")
        obj_p = [obj_p[idx] for idx in sort_idx]

        # æ„å»ºæç¤º
        prompt_content = self.get_prompt(x_p, y_p, obj_p)

        if debug_mode:
            print("ğŸ¤– æç¤ºå†…å®¹:")
            print(prompt_content)
            print("> æŒ‰å›è½¦ç»§ç»­")
            input()

        # æ ¹æ®ç«¯ç‚¹ç±»å‹é€‰æ‹©APIè°ƒç”¨æ–¹å¼
        if "localhost" in endpoint or "127.0.0.1" in endpoint:
            # æœ¬åœ°Ollama
            response = self.call_ollama_api(prompt_content, model_LLM, endpoint)
        else:
            # OpenAIæˆ–å…¶ä»–å…¼å®¹API
            response = self.call_openai_api(prompt_content, model_LLM, endpoint, key)

        if response is None:
            print("âŒ æ‰€æœ‰APIè°ƒç”¨å¤±è´¥ï¼Œè¿”å›éšæœºè§£")
            # è¿”å›éšæœºè§£ä½œä¸ºåå¤‡
            off1 = np.random.rand(len(x_p[0]))
            off2 = np.random.rand(len(x_p[0]))
        else:
            # è§£æå“åº”
            matches = re.findall(r"<start>(.*?)<end>", response)
            
            if len(matches) >= 2:
                try:
                    off_string1 = matches[0]
                    off1 = np.fromstring(off_string1, sep=",", dtype=float)
                    
                    off_string2 = matches[1]
                    off2 = np.fromstring(off_string2, sep=",", dtype=float)
                    
                    print(f"âœ… æˆåŠŸè§£æå‡º {len(matches)} ä¸ªè§£")
                except Exception as e:
                    print(f"âŒ è§£æå“åº”å¤±è´¥: {str(e)}")
                    off1 = np.random.rand(len(x_p[0]))
                    off2 = np.random.rand(len(x_p[0]))
            else:
                print(f"âš ï¸  åªæ‰¾åˆ° {len(matches)} ä¸ªè§£ï¼Œä½¿ç”¨éšæœºè§£è¡¥å……")
                off1 = np.random.rand(len(x_p[0]))
                off2 = np.random.rand(len(x_p[0]))

        # ä¿å­˜è®°å½•
        if out_filename is not None:
            try:
                with open(out_filename, "a") as file:
                    for i in range(len(x_p)):
                        for j in range(len(x_p[i])):
                            file.write("{:.4f} ".format(x_p[i][j]))
                        file.write("{:.4f} ".format(y_p[i]))
                    for i in range(len(off1)):
                        file.write("{:.4f} ".format(off1[i]))
                    for i in range(len(off1)):
                        file.write("{:.4f} ".format(off2[i]))
                    file.write("\n")
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜è®°å½•å¤±è´¥: {str(e)}")

        # è¾¹ç•Œå¤„ç†
        off1 = np.clip(off1, 0.0, 1.0)
        off2 = np.clip(off2, 0.0, 1.0)
        
        # åå˜æ¢
        off1 = np.array([[(off1 * (_.xu - _.xl) + _.xl)]])
        off2 = np.array([[(off2 * (_.xu - _.xl) + _.xl)]])
        off = np.append(off1, off2, axis=0)

        if debug_mode:
            print("ğŸ¯ æœ€ç»ˆç»“æœ:")
            print(f"å“åº”: {response}")
            print(f"è§£1: {off1}")
            print(f"è§£2: {off2}")
            print("> æŒ‰å›è½¦ç»§ç»­")
            input()

        return off


class GPT_OpenAI_interface(GPT_OpenAI):
    """GPT OpenAIæ¥å£ç±»"""

    def __init__(self, **kwargs):
        super().__init__(n_new=1, **kwargs) 